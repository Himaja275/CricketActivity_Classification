{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db83518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc1cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train data\n",
    "mat_data = scipy.io.loadmat(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\purified_cric1\\train.mat\")\n",
    "mat_variable = mat_data['traindata']\n",
    "data_array = np.array(mat_variable)\n",
    "column_names = [f'C{i}' for i in range(1, data_array.shape[1] + 1)]\n",
    "train = pd.DataFrame(data_array, columns=column_names)\n",
    "train.rename(columns={'C10': 'Class_label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test data\n",
    "mat_data = scipy.io.loadmat(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\purified_cric1\\test.mat\")\n",
    "mat_variable = mat_data['testdata']\n",
    "data_array = np.array(mat_variable)\n",
    "column_names = [f'C{i}' for i in range(1, data_array.shape[1] + 1)]\n",
    "test = pd.DataFrame(data_array, columns=column_names)\n",
    "test.rename(columns={'C10': 'Class_label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad506bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libreries\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "from tensorflow import reshape\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D,AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv1D\n",
    "from tensorflow.keras.layers import ZeroPadding2D,ZeroPadding1D, MaxPooling2D, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU, SimpleRNN\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40989c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[\"Class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b9ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f26bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ded4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6fbca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:,0:N_FEATURES]=scaler.transform(train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(test.iloc[:,0:N_FEATURES])\n",
    "test.iloc[:,0:N_FEATURES]=scaler.transform(test.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2075b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIODS = 1000\n",
    "STEP_DISTANCE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments_and_labels(df, time_steps,step,n_features, label_name):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df), step):\n",
    "      for j in range(1, n_features+1):\n",
    "        L = ('C'+str(j)) \n",
    "        segments.append(df[str(L)].values[i: i + time_steps])\n",
    "      label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "      labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 1e-3\n",
    "   drop = 0.1\n",
    "   epochs_drop = 70.0\n",
    "   lrate = initial_lrate * tf.math.pow(drop,  \n",
    "           tf.math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "train[LABEL] = le.fit_transform(train['Class_label'].values.ravel())\n",
    "# df_Valid[LABEL] = le.fit_transform(df_Valid['Class_label'].values.ravel())\n",
    "test[LABEL] = le.fit_transform(test['Class_label'].values.ravel())\n",
    "print('df_train_size',train)\n",
    "# print('df_valid_size',df_Valid)\n",
    "print('df_test_size',test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3620f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = create_segments_and_labels(train,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# print(x_train)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print('y_train shape: ', y_train.shape)\n",
    "# Set input & output dimensions\n",
    "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "print(num_time_periods)\n",
    "print(num_sensors)\n",
    "num_classes = le.classes_.size\n",
    "print(list(le.classes_))\n",
    "# input_shape = (num_time_periods,num_sensors)\n",
    "# print(input_shape)\n",
    "input_shape = (num_time_periods,num_sensors)\n",
    "#x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "print('x_train shape:', x_train[0].shape)\n",
    "print('input_shape:', input_shape)\n",
    "x_train = x_train.astype('float32')\n",
    "# x_train = [torch.tensor(arr, dtype=torch.float32) for arr in x_train]\n",
    "# y_train = y_train.astype('float32')\n",
    "# print(y_train)\n",
    "y_train_hot = np_utils.to_categorical(y_train, num_classes)\n",
    "print(y_train_hot)\n",
    "# y_train_hot= [torch.tensor(arr, dtype=torch.uint8) for arr in y_train_hot]\n",
    "print('New y_train shape: ', y_train_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = create_segments_and_labels(test,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "# print(x_train)\n",
    "print(x_test.shape[0], 'testing samples')\n",
    "print('y_test shape: ', y_test.shape)\n",
    "# Set input_shape / reshape for Keras\n",
    "#x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "x_test = x_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "y_test_hot = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_length = 40,25\n",
    "n_depth=9\n",
    "x_train = x_train.reshape(x_train.shape[0], n_steps, n_length,n_depth)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# x_valid = x_valid.reshape(x_valid.shape[0], n_steps, n_length, n_depth)\n",
    "# print('x_valid shape: ', x_valid.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], n_steps, n_length,n_depth)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "n_outputs = y_train_hot.shape[1]\n",
    "print('n_outputs',n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=[]\n",
    "for i in range(1,n_outputs+1,1):\n",
    "  LABELS.append (i)\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 300, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48aba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=9, padding='same', kernel_initializer=\"he_normal\",strides=2,kernel_regularizer=l1(1e-04)), \\\n",
    "                           input_shape=(n_steps,n_length,n_depth)))\n",
    "model.add(TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=8,strides=2)))\n",
    "model.add(TimeDistributed(Activation('tanh')))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=5,padding=\"same\",kernel_initializer=\"he_normal\",strides=2,kernel_regularizer=l1(1e-04))))\n",
    "model.add(TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)))\n",
    "model.add(TimeDistributed(Activation('tanh')))\n",
    "model.add(TimeDistributed(Dropout(0.2093)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=5,padding=\"same\",kernel_initializer=\"he_normal\",strides=2,kernel_regularizer=l1(1e-04))))\n",
    "model.add(TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)))\n",
    "model.add(TimeDistributed(Activation('tanh')))\n",
    "model.add(TimeDistributed(Dropout(0.2093)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3,padding=\"same\",kernel_initializer=\"he_normal\",strides=2,kernel_regularizer=l1(1e-04))))\n",
    "model.add(TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)))\n",
    "model.add(TimeDistributed(Activation('tanh')))\n",
    "model.add(TimeDistributed(Dropout(0.2093)))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "# model.add(Flatten())\n",
    "model.add(Bidirectional(LSTM(200,return_sequences=True)))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(200,return_sequences=True)))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "# model.add(Bidirectional(LSTM(200,return_sequences=True)))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Bidirectional(LSTM(200,return_sequences=True)))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Flatten())\n",
    "# model.add(BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None))\n",
    "# model.add(Bidirectional(LSTM(200)))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(2000, activation='tanh'))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "# model.add(Dense(200, activation='tanh'))\n",
    "model.add(BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None))\n",
    "model.add(Dense(n_outputs, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e14150",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "checkpoint_filepath = '/media/naveen/nav/mat_codes/nina_DB2_codes/prep_no_prep/CNN100X100/checkpoint.hdf5'\n",
    "# model.load_weights(checkpoint_filepath) \n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,verbose=1, monitor='val_accuracy',save_weights_only=True,save_best_only=True)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=75, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02481b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=[]\n",
    "for i in range(1,n_outputs+1,1):\n",
    "  LABELS.append (i)\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(r'C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\purified_cric1\\telidu.csv', append=True, separator=';')\n",
    "history = model.fit(x_train, y_train_hot, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger,checkpoint_callback,lrate],validation_data=(x_test, y_test_hot), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd6fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
