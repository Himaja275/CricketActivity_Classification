{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac716587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libreries\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "from tensorflow import reshape\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D,AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv1D\n",
    "from tensorflow.keras.layers import ZeroPadding2D,ZeroPadding1D, MaxPooling2D, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU, SimpleRNN\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eae7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def historyVisualization(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    plt.plot(history.history['mean_absolute_error'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['MSE', 'MAE'], loc='upper left')\n",
    "    plt.show()\n",
    "def plotPredict(y_pred, y_test):\n",
    "    plt.title('Predicted vs Actual')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('value')\n",
    "    plt.plot(y_pred, label='Predicted')\n",
    "    plt.plot(y_test, label='Actual ')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a864d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_basic_dataframe_info(dataframe):\n",
    "    # Shape and how many rows and columns\n",
    "    print('Number of rows in the dataframe: %i\\n' % (dataframe.shape[0]))\n",
    "    print('Number of columns in the dataframe: %i' % (dataframe.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36acb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train data\n",
    "mat_data = scipy.io.loadmat(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\purified_cric1\\train.mat\")\n",
    "mat_variable = mat_data['traindata']\n",
    "data_array = np.array(mat_variable)\n",
    "column_names = [f'C{i}' for i in range(1, data_array.shape[1] + 1)]\n",
    "train = pd.DataFrame(data_array, columns=column_names)\n",
    "train.rename(columns={'C10': 'Class_label'},inplace=True)\n",
    "show_basic_dataframe_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dca7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test data\n",
    "mat_data = scipy.io.loadmat(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\purified_cric1\\test.mat\")\n",
    "mat_variable = mat_data['testdata']\n",
    "data_array = np.array(mat_variable)\n",
    "column_names = [f'C{i}' for i in range(1, data_array.shape[1] + 1)]\n",
    "test = pd.DataFrame(data_array, columns=column_names)\n",
    "test.rename(columns={'C10': 'Class_label'},inplace=True)\n",
    "show_basic_dataframe_info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcb11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da741b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Class_label'].value_counts().plot(kind='bar',\n",
    "                                   title='Training Samples count for each class')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.ylabel('Total Samples')\n",
    "plt.xlabel('classes')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x',tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ed06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Class_label'].value_counts().plot(kind='bar',\n",
    "                                   title='Testing Samples count for each class')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.ylabel('Total Samples')\n",
    "plt.xlabel('classes')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x',tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 9\n",
    "scaler = preprocessing.StandardScaler().fit(train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "train[LABEL] = le.fit_transform(train['Class_label'].values.ravel())\n",
    "# df_Valid[LABEL] = le.fit_transform(df_Valid['Class_label'].values.ravel())\n",
    "test[LABEL] = le.fit_transform(test['Class_label'].values.ravel())\n",
    "print('df_train_size',train)\n",
    "# print('df_valid_size',df_Valid)\n",
    "print('df_test_size',test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87684b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 function to segment data into trial lengths (trial length =513 samples in this dataset)\n",
    "def create_segments_and_labels(df, time_steps,step,n_features, label_name):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "      for j in range(1, n_features+1):\n",
    "        L = ('C'+str(j)) \n",
    "        segments.append(df[str(L)].values[i: i + time_steps])\n",
    "      label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "      labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57993aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 1000\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_segments_and_labels(train,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# print(x_train)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print('y_train shape: ', y_train.shape)\n",
    "# Set input & output dimensions\n",
    "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "print(num_time_periods)\n",
    "print(num_sensors)\n",
    "num_classes = le.classes_.size\n",
    "print(list(le.classes_))\n",
    "# input_shape = (num_time_periods,num_sensors)\n",
    "# print(input_shape)\n",
    "input_shape = (num_time_periods,num_sensors)\n",
    "#x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "print('x_train shape:', x_train[0].shape)\n",
    "print('input_shape:', input_shape)\n",
    "x_train = x_train.astype('float32')\n",
    "# x_train = [torch.tensor(arr, dtype=torch.float32) for arr in x_train]\n",
    "# y_train = y_train.astype('float32')\n",
    "# print(y_train)\n",
    "y_train_hot = np_utils.to_categorical(y_train, num_classes)\n",
    "print(y_train_hot)\n",
    "# y_train_hot= [torch.tensor(arr, dtype=torch.uint8) for arr in y_train_hot]\n",
    "print('New y_train shape: ', y_train_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = create_segments_and_labels(test,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "# print(x_train)\n",
    "print(x_test.shape[0], 'testing samples')\n",
    "print('y_test shape: ', y_test.shape)\n",
    "# Set input_shape / reshape for Keras\n",
    "#x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "x_test = x_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "y_test_hot = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87064056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_steps, n_length = 20, 25\n",
    "# n_steps, n_length= 10, 50\n",
    "# n_steps, n_length= 16, 32\n",
    "n_steps, n_length = 40, 25\n",
    "n_depth=9\n",
    "x_train = x_train.reshape(x_train.shape[0], n_steps, n_length,n_depth)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# x_valid = x_valid.reshape(x_valid.shape[0], n_steps, n_length, n_depth)\n",
    "# print('x_valid shape: ', x_valid.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], n_steps, n_length,n_depth)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "n_outputs = y_train_hot.shape[1]\n",
    "print('n_outputs',n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce103d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 1e-3\n",
    "   drop = 0.1\n",
    "   epochs_drop = 70.0\n",
    "   lrate = initial_lrate * tf.math.pow(drop,  \n",
    "           tf.math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=[]\n",
    "for i in range(1,n_outputs+1,1):\n",
    "  LABELS.append (i)\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 200,512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(9,1), padding='same', kernel_initializer=\"he_normal\",strides=(3,1),kernel_regularizer=l1(1e-04), \\\n",
    "                           input_shape=(n_steps,n_length,n_depth)))\n",
    "model.add(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))\n",
    "model.add(MaxPooling2D(pool_size=(8,1),strides=(2,1)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,1),padding=\"same\",kernel_initializer=\"he_normal\",strides=(2,1),kernel_regularizer=l1(1e-04)))\n",
    "model.add(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2093))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='tanh',kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(n_outputs, activation='softmax',kernel_initializer=\"he_normal\"))\n",
    "adam=optimizers.Adam(lr=2.17e-3, beta_1=0.9, beta_2=0.999,epsilon=1e-08, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam=optimizers.Adam(lr=2.17e-3, beta_1=0.9, beta_2=0.999,epsilon=1e-08, amsgrad=False)\n",
    "adam=optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999,epsilon=1e-08, amsgrad=False)\n",
    "# sgd=optimizers.SGD(learning_rate=1e-3, momentum=0.9, nesterov=False, name='SGD')\n",
    "checkpoint_filepath = r\"C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\checkpoint.hdf5\"\n",
    "# model.load_weights(checkpoint_filepath) \n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,verbose=1, monitor='val_accuracy',save_weights_only=True,save_best_only=True)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb20766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     tf.keras.utils.plot_model(model, to_file='/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/olsson/CNN20X10/Model1.png',show_shapes=True,show_layer_names=True,dpi=96)\n",
    "csv_logger = CSVLogger(r'C:\\Users\\Dell\\OneDrive\\Desktop\\himi\\btp\\dataverse_files\\purified_cric1\\telidu.csv', append=True, separator=';')\n",
    "history = model.fit(x_train, y_train_hot, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger,checkpoint_callback,lrate,early],validation_data=(x_test, y_test_hot), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99831cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "print('epoch_number',best_index+1)\n",
    "print('train accuracy and validation accuracy', history.history['accuracy'][best_index], history.history['val_accuracy'][best_index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in history.history:\n",
    "    print(\"history\",i)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['accuracy'], 'r', label='Accuracy of training data')\n",
    "plt.plot(history.history['val_accuracy'], 'b', label='Accuracy of validation data')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b67151",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in history.history:\n",
    "    print(\"history\",i)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "plt.title('Model  Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath) \n",
    "_, testaccuracy = model.evaluate(x_test, y_test_hot, batch_size=batch_size, verbose=1)\n",
    "print('test_accuracy',testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(x_train)\n",
    "# Take the class with the highest probability from the train predictions\n",
    "max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "#max_y_train = np.argmax(y_train, axis=1)\n",
    "show_confusion_matrix(y_train, max_y_pred_train)\n",
    "print(classification_report(y_train, max_y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9914e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(x_test)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "max_y_test = np.argmax(y_test_hot, axis=1)\n",
    "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
    "print(classification_report(max_y_test, max_y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999cc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
